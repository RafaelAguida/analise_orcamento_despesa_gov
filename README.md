# ETL de OrÃ§amento e Despesa Governo Brasileiro - Portal da TransparÃªncia

## Fonte

[Portal da TransparÃªncia - Download Pastas](https://portaldatransparencia.gov.br/download-de-dados/orcamento-despesa)

[DicionÃ¡rio de Dados do Arquivo Bruto](https://portaldatransparencia.gov.br/pagina-interna/603417-dicionario-de-dados-orcamento-da-despesa)

---

## ğŸ“Œ DescriÃ§Ã£o do Projeto

Este projeto utiliza dados de **OrÃ§amento da Despesa do Governo Brasileiro**, disponÃ­veis no Portal da TransparÃªncia (link acima). Foram baixadas 12 pastas zipadas, uma para cada ano desde **2014**, e dentro de cada pasta hÃ¡ um **arquivo CSV** contendo os dados detalhados do orÃ§amento.

O objetivo Ã© realizar um **processo completo de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga)**, estruturando os dados em um modelo **Star Schema**. As tabelas sÃ£o organizadas em **dimensÃµes e fato**, permitindo anÃ¡lises para todas as partes interessadas.

Este projeto simula um cenÃ¡rio realista, onde um usuÃ¡rio insere arquivos em uma pasta de entrada para serem processados automaticamente com base nas regras do negÃ³cio. Esses arquivos podem ter origens diversas, como **sistemas internos**, **externos** ou **outras fontes de dados**.

A arquitetura do pipeline segue a estrutura de **camadas Bronze, Silver e Gold**, garantindo o armazenamento do **histÃ³rico bruto** para consultas futuras e refinando os dados em cada etapa do processamento.

O ETL conta com uma funÃ§Ã£o de **alertas via e-mail**, notificando em caso de falhas no processamento. As mensagens incluem **detalhes do erro** e ajudam na rÃ¡pida identificaÃ§Ã£o e resoluÃ§Ã£o do problema.

ğŸ”„ Estrutura do Pipeline ETL

O processo Ã© dividido em trÃªs etapas principais:

1ï¸âƒ£ **ExtraÃ§Ã£o**

Os arquivos CSV estÃ£o contidos em 12 pastas zipadas.

O script extracao.py realiza a leitura desses arquivos em uma pasta de partida que Ã© a arquivos_bronze/entrada e concatena os dados.

O arquivo concatenado Ã© salvo em arquivos_silver/entrada.

As pastas zipadas processadas sÃ£o movidas para arquivos_bronze/lidos.

2ï¸âƒ£ **TransformaÃ§Ã£o**

O script transformacao.py carrega o arquivo consolidado de arquivos_silver/entrada.

O arquivo Ã© movido para arquivos_silver/lidos antes do processamento.

As transformaÃ§Ãµes incluem:

- âœ… RenomeaÃ§Ã£o de colunas

- âœ… CorreÃ§Ã£o de tipos de dados

- âœ… SubstituiÃ§Ã£o de valores em algumas colunas

O resultado final Ã© salvo em arquivos_gold/entrada.

3ï¸âƒ£ **Carga**

O script carregamento.py carrega o CSV de arquivos_gold/entrada.

O arquivo carregado Ã© movido para arquivos_gold/lidos.

A partir desse arquivo, sÃ£o criadas 10 tabelas dimensÃµes e 1 tabela fato.

As tabelas finais (dimensÃµes e fato) sÃ£o armazenados em arquivos_gold/processadas, estruturadas em um modelo Star Schema.

---

## ğŸ“‚ Estrutura de DiretÃ³rios

```bash
etl_orcamento_despesa_gov/
â”œâ”€â”€ arquivos_bronze/
â”‚   â”œâ”€â”€ entrada/  # Pastas zipadas baixadas no site do governo, com CVS dentro de cada uma delas
â”‚   â”œâ”€â”€ lidos/    # Pastas zipadas processadas
â”œâ”€â”€ arquivos_silver/
â”‚   â”œâ”€â”€ entrada/  # Arquivo CSV consolidado
â”‚   â”œâ”€â”€ lidos/    # Arquivos processados
â”œâ”€â”€ arquivos_gold/
â”‚   â”œâ”€â”€ entrada/      # Arquivo pronto para carga
â”‚   â”œâ”€â”€ lidos/        # Arquivo jÃ¡ carregado
â”‚   â”œâ”€â”€ processadas/  # Tabelas finais geradas (dimensÃµes e fato)
â”œâ”€â”€ scripts/          
â”‚   â”œâ”€â”€ extracao.py      
â”‚   â”œâ”€â”€ transformacao.py
â”‚   â”œâ”€â”€ carregamento.py
â”‚   â”œâ”€â”€ utils.py
â”œâ”€â”€ notebooks_dev/      # Usados para desenvolvimento apenas
â”‚   â”œâ”€â”€ extracao_dev.ipynb
â”‚   â”œâ”€â”€ transformacao_dev.ipynb
â”‚   â”œâ”€â”€ carregamento_dev.ipynb
â”œâ”€â”€ main.py      # Script principal que chama todas as funÃ§Ãµes do ETL
â”œâ”€â”€ .env  # ConfiguraÃ§Ãµes sensÃ­veis (senhas, paths, etc.)
```

---

## ğŸ›  Tecnologias Utilizadas

Python (pandas, zipfile, os, dotenv)

Power BI para anÃ¡lise e visualizaÃ§Ã£o de dados

Arquitetura Star Schema para modelagem dos dados

---

## â–¶ï¸ Como Executar

Antes de comeÃ§ar, **certifique-se de que o Python estÃ¡ instalado**. Para verificar, execute:  
```bash
python --version
```
Se nÃ£o estiver instalado, baixe em: https://www.python.org/downloads/

1. Clone o repositÃ³rio em uma nova pasta

```bash
git clone https://github.com/RafaelAguida/analise_orcamento_despesa_gov.git
cd analise_orcamento_despesa_gov
```

2. Crie um ambiente virtual e ative

```bash
python -m venv venv
# No Windows:
venv\Scripts\activate
# Se der erro, execute
Set-ExecutionPolicy Unrestricted -Scope Process
venv\Scripts\activate
# No macOS/Linux:
source venv/bin/activate
```

3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

4. Configure o arquivo .env com as credenciais do seu email GMAIL (precisa ser uma senha de aplicativo, senha normal nao funciona via cÃ³digo)

5. Reset do ambiente, antes de rodar o pipeline, certifique-se de que os arquivos estejam organizados corretamente. Para isso, execute o comando abaixo

```bash
python scripts/reset_ambiente.py
```

6. Execute o main.py:

```bash
python main.py
```

---

## ğŸ“Š Resultados

ğŸš€ 11 tabelas geradas no formato **Star Schema**

ğŸ” Dados prontos para consumo no Power BI

âš¡ AutomatizaÃ§Ã£o do pipeline de ETL

ğŸ“© Monitoramento proativo, notificaÃ§Ãµes por e-mail em caso de falha no processo

ğŸ–¥ï¸ SimulaÃ§Ã£o de cenÃ¡rio realista, o usuÃ¡rio insere arquivos na pasta de entrada, simulando extraÃ§Ã£o de um sistema interno ou externo
